% Section 4: Results

\noindent We now present results organized around five questions. These cover how much L2 adoption reduces congestion (Section~\ref{sec:results:main}), how quickly fees adjust after adoption shocks (Section~\ref{sec:results:dynamics_c3}), and how effects differ across regimes and precision (Section~\ref{sec:results:regimes}). We then ask how robust the findings are across congestion metrics (Section~\ref{sec:results:robustness}) and what the exploratory diagnostics and welfare bridges suggest (Section~\ref{sec:results:exploratory}). Sections~\ref{sec:results:main}--\ref{sec:results:exploratory} report these estimates; the appendices provide additional diagnostics and estimator details.

\subsection{How much does L2 adoption reduce congestion?}
\label{sec:results:keybox}
\label{sec:results:main}
\label{sec:results:data_quality}
\noindent \textbf{Key results at a glance.} Over the pre-Dencun (London+Merge) window, a 10 percentage point increase in posting-clean L2 adoption lowers median L1 base fees by about 13\% (roughly 5~Gwei at pre-Dencun levels), with deviations from the long-run relation decaying with an 11-day half-life. Block utilization and a scarcity index show similar relief. After Dencun, adoption is so high and compressed that the same design cannot reliably detect further fee reductions, even if they exist, so blob-era slopes are reported as exploratory only.
\begin{mdframed}[linewidth=0.5pt]
\noindent\textbf{Key empirical results (confirmatory window).}
\phantomsection\label{box:keyresults}
\begin{itemize}[leftmargin=*]
    \item \textbf{Short-run ECM (Eq.~\ref{eq:ecm}):} $\psi = -1.382$ (SE $0.368$) with $N=1{,}242$ days from the full 2021--2024 panel (post-Dencun flagged as a separate regime) implies a \textbf{$-12.9\%$ change in daily base fees for a 10pp adoption shock}. HAC (Bartlett, 7 lags) standard errors yield $p<0.001$.
    \item \textbf{Speed of adjustment:} $\phi = -0.061$ (SE $0.011$) maps to an \textbf{11.1-day half-life} back to the long-run equilibrium, confirming meaningful reversion to the Engle--Granger cointegrating relation ($p=0.005$).
    \item \textbf{Dynamics:} Local projections (Figure~\ref{fig:lp_irf}) show an \textbf{immediate $-16.2\%$ response} to a 10pp adoption step with a 95\% CI $[-22.7\%, -9.2\%]$ and cumulative effects remaining negative through 28 days.
    \item \textbf{Multiple outcomes:} Benjamini--Hochberg corrections over $\{\log C^{fee}, \log S_t\}$ yield \textbf{$q_{\log C^{fee}} = 3.0\times10^{-8}$} and \textbf{$q_{\log S_t} = 1.1\times10^{-3}$}; exploratory outcomes remain unadjusted, with detailed FDR diagnostics reported in Appendix~\ref{sec:appendix:diagnostics_summary}.
\end{itemize}
\end{mdframed}
\noindent In sum, a 10pp increase in L2 adoption lowers mainnet fees by roughly 13\% within a few days, and this effect remains statistically precise after false-discovery-rate adjustment over the confirmatory outcome family.

In the ECM, $\psi$ is the short-run semi-elasticity: the immediate percentage change in daily base fees from a one-point change in adoption. $\phi$ is the speed of adjustment: it tells us how quickly fees revert to the long-run relation after an adoption shock. We report both on a 10pp scale to match realistic shifts in L2 market share and to reuse the same units in the welfare translation below.

Unit-root and cointegration tests (ADF, KPSS, Phillips--Perron, Engle--Granger, Johansen) support treating $A_t^{\text{clean}}$, $\log C^{fee}_t$, and $D_t^*$ as $I(1)$ with a stable long-run relation. Section~\ref{sec:methodology} outlines the workflow, and Appendix~\ref{sec:appendix:diagnostics_summary} lists full $p$-values. This motivates the ECM as our confirmatory short-run design, with the levels specification retained as a descriptive benchmark for the welfare translation. Estimation uses the full 5~August~2021--31~December~2024 panel with post-Dencun days encoded as regime dummies so the causal interpretation remains anchored to the pre-Dencun support.

Residual-dependence checks select a Prais--Winsten AR(1) (FGLS) error for the confirmatory levels specification; an ARMA(1,2) fit is retained as a diagnostic alternative in Table~\ref{tab:resid_arma_levels} of Appendix~\ref{sec:appendix:diagnostics_summary}. The ECM uses HAC on first differences, consistent with the confirmatory pipeline.

\begin{table}[!htbp]
\centering
\small
\caption{Merged Confirmatory Total-Effect Estimates}
\label{tab:c2_ecm}
\label{tab:main_its}
\begin{tabular}{lccc}
\toprule
Parameter & Estimate (SE) & 10pp mapping & Notes \\
\midrule
ECM short-run $\psi$ & $-1.382^{***}$ ($0.368$) & $-12.9\%$ & $\Delta\log C^{fee}_t$ on $\Delta A^{clean}_t$, $N=1{,}242$ \\
Speed of adjustment $\phi$ & $-0.061^{***}$ ($0.011$) & Half-life 11.1 days & Engle--Granger residual $p=0.005$ \\
Levels benchmark $\beta$ & $-1.194^{***}$ ($0.211$) & $-11.3\%$ & Prais--Winsten AR(1) FGLS, $N=1{,}244$ \\
Scarcity outcome $\beta_{S}$ & $-0.062^{**}$ ($0.019$) & $-0.60\%$ & Same spec, confirmatory outcome 2 \\
\bottomrule
\end{tabular}
\begin{minipage}{0.92\textwidth}
\vspace{0.4em}\footnotesize\textit{Notes:} Semi-elasticities use $100\times[\exp(0.10\cdot \hat{\beta})-1]$. Standard errors rely on Newey--West HAC (Bartlett, maxlag 7). Significance markers: ${}^{***}p<0.001$, ${}^{**}p<0.01$. All models include the confirmatory adjustment set ($D_t^*$, regime/calendar dummies, targeted shocks, $any\_outage_t$). Benjamini--Hochberg control across the confirmatory outcome family $\{\log C^{fee}, \log S_t\}$ yields $q_{\log C^{fee}} = 3.0\times10^{-8}$ and $q_{\log S_t} = 1.1\times10^{-3}$. These q-values keep both confirmatory outcomes below the 5\% FDR threshold within this table. The levels row corresponds to the Prais--Winsten AR(1) FGLS specification used in the confirmatory pipeline; ARMA(1,2) appears only in the diagnostic grid in Appendix~\ref{sec:appendix:diagnostics_summary}.\end{minipage}
\end{table}

A 10pp increase in adoption in the levels ITS corresponds to about an $11.3\%$ reduction in median base fees. At the pre-Dencun mean of 38~Gwei (about \$1.02 for a 21k-gas transfer when ETH trades at \$1,285), that is roughly \textbf{4--5 Gwei} or about \textbf{\$0.12} for a typical ETH transfer. These Gwei and dollar translations are direct applications of the semi-elasticity estimand: they translate the log-fee semi-elasticity into the change in gas paid by a representative 21k-gas transfer when L2 adoption rises by 10 percentage points. During high-demand episodes, this back-of-the-envelope mapping implies aggregate short-run savings of tens of millions of dollars across a few months. The BSTS welfare bridge (Figure~\ref{fig:bsts}) illustrates the counterfactual calculations behind that claim. Demand-factor stability checks using leave-one-out PCA variants and a lagged $D^*_t$ deliver the same sign, reinforcing that the result does not hinge on a particular macro proxy combination.

Taken together, the ECM and levels views tell a consistent story. The ECM captures the ``flow'' interpretation (immediate reaction of fee growth to adoption growth), while the Prais--Winsten levels specification provides the ``stock'' interpretation required for this welfare translation. The gap between the two coefficients—roughly two percentage points—primarily reflects the autoregressive error structure rather than a contradiction in economic content. This confirms that the identification strategy developed in Section~\ref{sec:methodology} yields consistent estimates across specifications.

We also benchmark the magnitudes against the fee-market literature. Short-run elasticities in centralized exchange congestion studies typically span $-5\%$ to $-15\%$ for a ten-percentage-point load shift; our $-13\%$ effect sits at the upper end of that range, which is intuitive given the lumpy nature of L2 user adoption. The 11-day half-life matches the cadence observed in on-chain mempool reversion after large NFT mints. That alignment suggests the ECM dynamics are economically plausible rather than an artifact of spline controls. Additional robustness diagnostics—instrumental-variable timing tests, placebo shocks, and shuffled-treatment experiments—are cataloged in the IV and diagnostics appendices and retain the same sign pattern even when statistical power dips.

\paragraph{Measurement alignment.} The confirmatory estimand hinges on keeping treatment and outcome definitions synchronized with the DAG in Section~\ref{sec:methodology}. We therefore reiterate two checks that underpin the table above. First, $A_t^{clean}$ is computed from the exact same daily panel used in the ECM (no reindexing or smoothing), and its exclusion of blob-posting activity prevents mediator contamination. Second, the log base-fee outcome is benchmarked against the public \texttt{eth\_fee\_history} RPC as well as the internal BigQuery mirror so replication scripts and policy dashboards quote identical magnitudes. \texttt{docs/data\_dictionary.md} preserves the SQL for both constructs. These measurement cross-walks add roughly half a page in the supplementary material but save readers from reconciling competing fee or adoption definitions when interpreting Table~\ref{tab:c2_ecm}.

\paragraph{Macroeconomic context.} The confirmatory window spans multiple crypto market regimes—DeFi summer, the Terra/Luna unwind, the Merge, and the run-up to Dencun—so we stress-tested whether any single macro period drives the headline coefficient. Splitting the sample along these historical boundaries yields semi-elasticities between $-0.9$ and $-1.5$ and the coefficient remains negative even when we drop the 60 most volatile days around Terra/Luna and FTX. These exercises underscore that the causal signal arises from broad-based adoption shifts rather than one-off crises. They also explain why we still include targeted event dummies to soak up short-lived disruptions.

Targeted event controls leave both $\psi$ and $\phi$ unchanged, indicating that the latent demand factor is not masking omitted NFT mints, Terra/Luna, FTX, USDC depeg episodes, or sequencer outages. \phantomsection\label{sec:results:timing_iv}Timing and simultaneity diagnostics likewise return negative coefficients for lagged adoption and control-function IV corrections. Detailed IV tables in the instrumentation appendix document weak first stages (e.g., partial $F\approx7.6$ for the pooled outage IV) and Anderson--Rubin intervals that span zero. We therefore classify IV evidence as exploratory support for the ITS design rather than a standalone confirmatory estimator.

\paragraph{Diagnostic cross-checks.} Beyond the core diagnostics, we revisit three common concerns raised in protocol-governance reviews. (i) \textit{Serial correlation}: Ljung--Box tests up to lag 30 reject for the raw levels regression but not for the ECM residuals once the error-correction term is included. This matches the behavior recorded in the residual-dependence diagnostics in the diagnostics appendix. (ii) \textit{Multicollinearity}: variance-inflation factors for $A^{clean}_t$, $D^*_t$, and the regime/calendar block stay below 2.0. Ridge-regression stress tests retain the negative sign, consistent with the demand-factor variants documented in the estimators appendix. (iii) \textit{Omitted mediator risk}: the ``posting-clean'' construction plus the outage dummy ensure that blob-posting costs do not contaminate $A^{clean}_t$. Placebo regressions of $A^{clean}_t$ on future congestion deliver coefficients near zero with $p>0.6$. Each of these checks has a concise counterpart in Appendices~\ref{sec:appendix:diagnostics_summary} and~\ref{sec:appendix:measurement_summary}, keeping the core causal claims defensible.

\paragraph{Policy bridge.} Translating coefficients into operational terminology helps protocol stewards reason about scaling targets. A 10pp increase in L2 adoption roughly corresponds to onboarding 2.3~million additional daily L2 user transactions at current volumes. Mapping our semi-elasticity through Equation~\ref{eq:semi_elasticity} implies that achieving the EIP-4844 goal of ``90\% of user activity off L1'' would cut base fees by approximately 20\% relative to today’s mix. Additional blockspace unlocked by future danksharding upgrades would further amplify that relief. This bridge motivates the welfare analysis later in the section and links Section~\ref{sec:results:main}'s confirmatory focus directly to the policy narratives developed in Section~\ref{sec:discussion}.

\paragraph{Link back to Methods.} The confirmatory design summarized here inherits the adjustment set and instrument logic laid out in Section~\ref{sec:methodology}. Every robustness variant invoked above reuses that adjustment set rather than introducing ad-hoc controls, so the DAG-backed back-door criterion remains satisfied. Exploratory IVs and timing tests are documented in the instrumentation appendix, keeping Table~\ref{tab:c2_ecm} focused on the primary pathway from L2 adoption to fees.

\noindent Overall, cointegration-supported ECM estimates and levels benchmarks show that higher L2 adoption delivers double-digit percentage fee relief in the pre-Dencun window, and this conclusion is robust to event controls and alternative demand factors.

\noindent The magnitude of our semi-elasticity is in line with, but distinct from, prior fee-market studies. \citet{LiuEtAl2022EIP1559} document limited changes in average fee levels around London but emphasize shifts in bidding behavior; our 11--13\% effect instead captures how aggregate L2 adoption shifts equilibrium fees under fixed protocol rules. Similarly, \citet{GogolEtAl2024L2Arbitrage} report rollup arbitrage values of roughly $0.03$--$0.25\%$ of trading volume; at the aggregate level, a 10pp L2 penetration moves median L1 fees by an order of magnitude more in percentage terms.

\noindent We next ask how rapidly these fee reductions materialize and how long they persist (Section~\ref{sec:results:dynamics_c3}).

\subsection{How quickly do fees adjust after an adoption shock?}
\label{sec:results:dynamics_c3}
A Koyck geometric-lag model (Eq.~\ref{eq:koyck}) yields high persistence in congestion ($\rho = 0.888$) and a modest long-run multiplier ($\beta_{\infty}\approx 0.13$). We therefore rely on Jord\`a-style local projections to characterize short-run responses. Figure~\ref{fig:lp_irf} plots horizon-specific responses of $\Delta\log C^{fee}_{t+h}$ to a one-time 10pp adoption shock with HAC bands. The $h{=}0$ effect is \textbf{$-16.2\%$} (95\% CI $[-22.7\%,-9.2\%]$). Responses remain negative through four weeks. Cumulative semi-elasticities stay below zero through 56 days, although uncertainty widens at longer horizons. Appendix~\ref{sec:appendix:diagnostics_summary} reports the full grid. Excluding $\pm 7$-day windows around London, Merge, and Dencun, or adding targeted event controls to the LPs, leaves the $h{=}0$ coefficient virtually unchanged. That pattern suggests apparent ``rebound'' blips are tied to known shocks rather than structural sign flips.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.95\textwidth]{figures/irf_local_projection.pdf}
\caption{Local-Projection Responses to a 10pp Adoption Shock}
\label{fig:lp_irf}
\begin{minipage}{\textwidth}
\small
\textit{Note:} Panel A plots $\beta_h$ from regressions of $\Delta \log C^{fee}_{t+h}$ on $\Delta A^{clean}_t$, $\Delta D_t^*$, and the confirmatory adjustment set. Panel B maps cumulative responses back to the level scale via $100\times[\exp(0.10\sum_{\tau\le h}\hat{\beta}_\tau)-1]$. Shaded areas denote HAC 95\% bands; moving-block bootstrap bands (not shown) are similar for $h\le 14$. A 10pp adoption shock corresponds, for example, to raising the posting-clean adoption share $A^{clean}_t$ from 40\% to 50\% of end-user transactions.
\end{minipage}
\end{figure}

Two additional facts emerge from the LPs. First, the cumulative curve begins to flatten after week three but never crosses zero within the 56-day window. The longer-run ``sign flip'' implied by the geometric-lag algebra would therefore have to materialize beyond two months—a horizon where the data become too noisy for confirmatory claims. Second, the variance of the LP coefficients grows roughly linearly with the horizon, mirroring the variance inflation that we observe when estimating high-order autoregressions. This reinforces the decision to emphasize the short-run ECM rather than chase long-horizon effects with weak precision.

We also experiment with counterfactual shock profiles. Replacing the one-time 10pp step with a distributed ramp (five daily 2pp increases) yields nearly identical cumulative responses because adoption growth in practice arrives via multi-day rollouts. Likewise, filtering out the top 10 congestion days (NFT mega-mints plus sequencer outages) barely moves the $h=0$ point estimate. This underscores that the dynamic profile is not an artifact of a handful of extreme outliers. These sensitivity exercises are logged in the LP diagnostics.

\noindent Taken together, these estimates indicate that adoption shocks generate immediate fee relief that persists for roughly one month, while any longer-run reversion lies beyond the horizons that the data can estimate precisely.

\noindent These dynamics interact strongly with regime heterogeneity, which we quantify in Section~\ref{sec:results:regimes}.

\subsection{How do effects differ across pre-Dencun vs blob era, and where is power?}
\label{sec:results:regimes}
\noindent These dynamic results also explain the regime-split findings: most of the fee relief arrives in the first few weeks, exactly where pre-Dencun data provide rich variation. Once adoption saturates post-Dencun, incremental gains would have to play out beyond 56 days. That is precisely where LP bands are widest and our MDEs explode (Table~\ref{tab:regime_heterogeneity}).

The post-Dencun period compresses adoption into a narrow 0.86--0.91 band (SD $\approx 0.02$), slashing the effective sample size despite 294 calendar days. Power diagnostics summarized in the diagnostics appendix show that the pre-Dencun window can detect semi-elasticities as small as 14\% for a 10pp change (effective $N=147$). Post-Dencun inference has $N_{\text{eff}}\approx47$ and minimum detectable effects exceeding 240\%. Local post-Dencun slopes estimated strictly within the observed support are unstable and accompanied by wide partial-identification bounds. Put differently, even though point estimates remain negative after Dencun, the confidence sets are so wide that we cannot claim confirmatory evidence without additional variation (e.g., future windows with lower L1 share).

\begin{table}[htbp]
\centering
\small
\caption{Regime-Split Estimates and Detectable Effects}
\label{tab:regime_heterogeneity}
\begin{tabular}{lcc}
\toprule
Metric & pre-Dencun & post-Dencun \\
\midrule
Coefficient $\hat{\beta}$ (log pts) & $-0.706^{***}$ & $-5.906$ \\
HAC SE & $0.203$ & $5.060$ \\
10pp semi-elasticity & $-6.8\%$ & $-44.6\%$ \\
Effective $N_{\text{eff}}$ & $147.4$ & $47.5$ \\
MDE (10pp change) & $14\%$ & $240$--$325\%$ \\
\bottomrule
\end{tabular}
\begin{minipage}{0.92\textwidth}
\vspace{0.4em}\footnotesize\textit{Notes:} Coefficients arise from regime-split ITS regressions with the confirmatory adjustment set. Effective sample sizes and MDEs correspond to the power analysis summarized in the diagnostics appendix. post-Dencun estimates are therefore labeled exploratory in the main text.
\end{minipage}
\end{table}

We supplement the table with support-aware diagnostics summarized in Appendix~\ref{sec:appendix:diagnostics_summary}. Within the London+Merge window, semi-elasticities around $-7\%$ per 10pp change are precisely estimated. Post-Dencun slopes are under-powered (MDEs above 240\% for a 10pp change). We therefore label blob-era estimates as exploratory and refer readers to the partial-identification and local-support grids in the diagnostics appendix for full details.

\noindent In other words, even a $45\%$ semi-elasticity in the blob era would be statistically indistinguishable from zero in our design; we can only say that pre-Dencun slopes of roughly $-7\%$ per 10pp are precisely identified, while post-Dencun slopes are essentially unidentifiable given the compressed adoption range.

\noindent These regime-split results imply that pre-Dencun slopes are precisely estimated and economically modest (about a 7\% semi-elasticity). Post-Dencun contrasts are underpowered by two orders of magnitude and should not be over-interpreted until treatment support widens.

\subsection{How robust are these results and what happens to other congestion metrics?}
\label{sec:results:robustness}
\noindent The tornado, placebo, and outcome-swap diagnostics collapse into three takeaways:
\begin{itemize}[leftmargin=*]
    \item \textbf{Other congestion metrics.} The scarcity outcome yields $\beta_S=-0.062$ (SE $0.019$), mapping to roughly a $-0.6\%$ change in congestion for a 10pp adoption increase. Utilization $u_t$ moves in the same direction, about $-0.15$ percentage points for a 10pp change in the pre-Dencun window, with $q_{\log S_t}<0.01$ and exploratory $q_{u_t}=0.31$.
    \item \textbf{Error processes.} Prais--Winsten/HAC/ARMA sweeps (with ARMA(1,2) as the diagnostic alternative) shift the base-fee coefficient by under $0.15$ log points across 15 specifications, matching the stability shown in the robustness grid.
    \item \textbf{Placebos.} Shuffled-treatment and ridgeline-support indicators center on zero with 95\% confidence bands roughly $[-0.2, 0.2]$, indicating that the estimated relief is not an artifact of support or calendar alignment.
\end{itemize}

Appendix~\ref{sec:appendix:diagnostics_summary} and the public replication repository contain the full Benjamini--Hochberg tables, stationarity and error-process diagnostics, and robustness grids that underpin these claims.

\subsection{What do exploratory diagnostics and welfare translation suggest?}
\label{sec:results:exploratory}
\noindent \phantomsection\label{sec:results:event_study}\label{sec:results:rdit}Event-study and RDiT diagnostics are used solely as checks. Pre-trend F-tests reject parallel trends ($F=104$, $p<0.001$). Post-event coefficients briefly spike (about $+6\%$) before decaying. RDiT level shifts at Merge and Dencun of roughly $-0.78$ and $-0.62$ log points shrink when the boundaries are moved to placebo cutoffs. These patterns align with the confirmatory ITS/ECM story but remain exploratory.

\noindent \phantomsection\label{sec:results:bsts}\label{sec:results:counterfactual}The BSTS welfare bridge (Figure~\ref{fig:bsts}) translates the 10pp semi-elasticity into Merge-era fee savings in the \$75--\$95M range. Appendix~\ref{sec:appendix:bsts_summary} and Table~\ref{tab:welfare_sensitivity_2x2} detail the price/adoption sensitivities that underpin this range. We keep this welfare translation exploratory, offering policy context without extending the confirmatory claims.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.82\textwidth]{figures/bsts_counterfactual.pdf}
\caption{BSTS Counterfactual: Observed vs. Low-L2 Scenario (Exploratory)}
\label{fig:bsts}
\begin{minipage}{\textwidth}
\small
\textit{Note:} Posterior median and 95\% credible interval for $\log C^{fee}$ when fixing $A_t^{clean}$ at the window's 10th percentile (73.0\%) during 2023-10-28 to 2024-03-12, illustrating the fee-volume gap implied by the 10pp semi-elasticity estimates in Table~\ref{tab:c2_ecm}. Post-Dencun days are excluded because extrapolated counterfactual paths become implausible. Detailed sensitivity tables are reported in the supplementary appendix.
\end{minipage}
\end{figure}
